{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "backups = pd.read_csv(\"https://raw.githubusercontent.com/datarescueproject/portal/refs/heads/main/baserow_exports/datarescue_backups.csv\")\n",
    "datasets = pd.read_csv(\"https://raw.githubusercontent.com/datarescueproject/portal/refs/heads/main/baserow_exports/datarescue_datasets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>notes</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>url</th>\n",
       "      <th>websites</th>\n",
       "      <th>organization</th>\n",
       "      <th>agency</th>\n",
       "      <th>last_modified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billion-Dollar Weather and Climate Disasters</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/billions/mapping</td>\n",
       "      <td>ncei.noaa.gov</td>\n",
       "      <td>National Oceanic and Atmospheric Administration</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Communities Survey (ACS)</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.census.gov/programs-surveys/acs</td>\n",
       "      <td>census.gov</td>\n",
       "      <td>Census Bureau</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLS Downloads</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>https://download.bls.gov</td>\n",
       "      <td>download.bls.gov</td>\n",
       "      <td>Bureau of Labor Statistics</td>\n",
       "      <td>Department of Labor</td>\n",
       "      <td>2025-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDC FTP</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>https://ftp.cdc.gov/</td>\n",
       "      <td>ftp.cdc.gov</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Department of Health and Human Services</td>\n",
       "      <td>2025-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US Census Bureau FTP</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>ftp://ftp.census.gov</td>\n",
       "      <td>census.gov</td>\n",
       "      <td>Census Bureau</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-02-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dataset notes  dataset_id  \\\n",
       "0  Billion-Dollar Weather and Climate Disasters                 1   \n",
       "1             American Communities Survey (ACS)                 3   \n",
       "2                                 BLS Downloads                 6   \n",
       "3                                       CDC FTP                 7   \n",
       "4                          US Census Bureau FTP                 8   \n",
       "\n",
       "                                                 url          websites  \\\n",
       "0  https://www.ncei.noaa.gov/access/billions/mapping     ncei.noaa.gov   \n",
       "1        https://www.census.gov/programs-surveys/acs        census.gov   \n",
       "2                           https://download.bls.gov  download.bls.gov   \n",
       "3                               https://ftp.cdc.gov/       ftp.cdc.gov   \n",
       "4                               ftp://ftp.census.gov        census.gov   \n",
       "\n",
       "                                      organization  \\\n",
       "0  National Oceanic and Atmospheric Administration   \n",
       "1                                    Census Bureau   \n",
       "2                       Bureau of Labor Statistics   \n",
       "3       Centers for Disease Control and Prevention   \n",
       "4                                    Census Bureau   \n",
       "\n",
       "                                    agency last_modified  \n",
       "0                   Department of Commerce    2025-02-10  \n",
       "1                   Department of Commerce    2025-03-03  \n",
       "2                      Department of Labor    2025-02-10  \n",
       "3  Department of Health and Human Services    2025-02-10  \n",
       "4                   Department of Commerce    2025-02-11  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.columns = datasets.columns.str.lower()\n",
    "datasets = datasets.fillna('')\n",
    "datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agencies = datasets.agency.value_counts().keys()\n",
    "categories = categories = ['arts-culture-history','health-human-services',\n",
    "'budget-finance','parks-recreation','economy','planning-zoning',\n",
    "'education','public-safety','elections-politics','real-estate-land-records',\n",
    "'environment','transportation','food','uncategorized']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "agency_to_category = {\n",
    "    'Department of Health and Human Services': 'Health / Human Services',\n",
    "    'Department of Commerce': 'Economy',\n",
    "    'Department of Housing and Urban Development': 'Real Estate / Land Records',\n",
    "    'Department of Veterans Affairs': 'Health / Human Services',\n",
    "    'National Endowment for the Humanities': 'Arts / Culture / History',\n",
    "    'AmeriCorps': 'Public Safety',\n",
    "    'Department of Education': 'Education',\n",
    "    'Federal Mediation and Conciliation Service': 'Economy',\n",
    "    'Department of Homeland Security': 'Public Safety',\n",
    "    'Department of Energy': 'Environment',\n",
    "    'National Labor Relations Board': 'Economy',\n",
    "    'Environmental Protection Agency': 'Environment',\n",
    "    'Consumer Financial Protection Bureau': 'Budget / Finance',\n",
    "    'Federal Housing Finance Agency': 'Real Estate / Land Records',\n",
    "    'Department of the Treasury': 'Budget / Finance',\n",
    "    'Institute of Museum and Library Services': 'Arts / Culture / History',\n",
    "    'Department of the Interior': 'Parks / Recreation',\n",
    "    'General Services Administration': 'Economy',\n",
    "    'Department of Labor': 'Economy',\n",
    "    'U.S. Agency for International Development': 'Health / Human Services',\n",
    "    'Department of Transportation': 'Transportation',\n",
    "    'National Aeronautics and Space Administration': 'Environment',\n",
    "    '': 'Uncategorized',\n",
    "    'Department of Justice': 'Public Safety',\n",
    "    'Department of the Interior, National Parks Service': 'Parks / Recreation',\n",
    "    'Department of State': 'Elections / Politics',\n",
    "    'National Science Foundation': 'Education',\n",
    "    'Department of Health and Human Services, Department of Commerce': 'Health / Human Services',\n",
    "    'Consumer Financial Protection Bureau, Federal Housing Finance Agency': 'Budget / Finance',\n",
    "    'U.S. Department of Agriculture': 'Food',\n",
    "    'Office of Management and Budget': 'Budget / Finance'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>status</th>\n",
       "      <th>url</th>\n",
       "      <th>source_website</th>\n",
       "      <th>organization</th>\n",
       "      <th>agency</th>\n",
       "      <th>download_date</th>\n",
       "      <th>size</th>\n",
       "      <th>maintainer</th>\n",
       "      <th>download_location</th>\n",
       "      <th>file_type</th>\n",
       "      <th>notes</th>\n",
       "      <th>metadata_available</th>\n",
       "      <th>metadata_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Billion-Dollar Weather and Climate Disasters</td>\n",
       "      <td>1</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://www.ncei.noaa.gov/access/billions/mapping</td>\n",
       "      <td>ncei.noaa.gov</td>\n",
       "      <td>National Oceanic and Atmospheric Administration</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-02-10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>HD</td>\n",
       "      <td>https://dataverse.harvard.edu/dataset.xhtml?pe...</td>\n",
       "      <td>ZIP</td>\n",
       "      <td></td>\n",
       "      <td>yes</td>\n",
       "      <td>https://dataverse.harvard.edu/dataset.xhtml?pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLS Downloads</td>\n",
       "      <td>6</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://download.bls.gov</td>\n",
       "      <td>download.bls.gov</td>\n",
       "      <td>Bureau of Labor Statistics</td>\n",
       "      <td>Department of Labor</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>47.0</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDC FTP</td>\n",
       "      <td>7</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://ftp.cdc.gov/</td>\n",
       "      <td>ftp.cdc.gov</td>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Department of Health and Human Services</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>213.0</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US Census Bureau FTP</td>\n",
       "      <td>8</td>\n",
       "      <td>Finished</td>\n",
       "      <td>ftp://ftp.census.gov</td>\n",
       "      <td>census.gov</td>\n",
       "      <td>Census Bureau</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-02-01</td>\n",
       "      <td>180.0</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Partial download, server is back online but co...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>National Hurricane Center (NHC)</td>\n",
       "      <td>9</td>\n",
       "      <td>Finished</td>\n",
       "      <td>https://www.nhc.noaa.gov/archive</td>\n",
       "      <td>nhc.noaa.gov</td>\n",
       "      <td>NOAA/National Hurricane Center</td>\n",
       "      <td>Department of Commerce</td>\n",
       "      <td>2025-02-06</td>\n",
       "      <td>61.0</td>\n",
       "      <td>DRP</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        dataset  dataset_id    status  \\\n",
       "0  Billion-Dollar Weather and Climate Disasters           1  Finished   \n",
       "1                                 BLS Downloads           6  Finished   \n",
       "2                                       CDC FTP           7  Finished   \n",
       "3                          US Census Bureau FTP           8  Finished   \n",
       "4               National Hurricane Center (NHC)           9  Finished   \n",
       "\n",
       "                                                 url    source_website  \\\n",
       "0  https://www.ncei.noaa.gov/access/billions/mapping     ncei.noaa.gov   \n",
       "1                           https://download.bls.gov  download.bls.gov   \n",
       "2                               https://ftp.cdc.gov/       ftp.cdc.gov   \n",
       "3                               ftp://ftp.census.gov        census.gov   \n",
       "4                   https://www.nhc.noaa.gov/archive      nhc.noaa.gov   \n",
       "\n",
       "                                      organization  \\\n",
       "0  National Oceanic and Atmospheric Administration   \n",
       "1                       Bureau of Labor Statistics   \n",
       "2       Centers for Disease Control and Prevention   \n",
       "3                                    Census Bureau   \n",
       "4                   NOAA/National Hurricane Center   \n",
       "\n",
       "                                    agency download_date   size maintainer  \\\n",
       "0                   Department of Commerce    2025-02-10   0.15         HD   \n",
       "1                      Department of Labor    2025-02-01   47.0        DRP   \n",
       "2  Department of Health and Human Services    2025-02-01  213.0        DRP   \n",
       "3                   Department of Commerce    2025-02-01  180.0        DRP   \n",
       "4                   Department of Commerce    2025-02-06   61.0        DRP   \n",
       "\n",
       "                                   download_location file_type  \\\n",
       "0  https://dataverse.harvard.edu/dataset.xhtml?pe...       ZIP   \n",
       "1                                                                \n",
       "2                                                                \n",
       "3                                                                \n",
       "4                                                                \n",
       "\n",
       "                                               notes metadata_available  \\\n",
       "0                                                                   yes   \n",
       "1                                                                         \n",
       "2                                                                         \n",
       "3  Partial download, server is back online but co...                      \n",
       "4                                                                         \n",
       "\n",
       "                                        metadata_url  \n",
       "0  https://dataverse.harvard.edu/dataset.xhtml?pe...  \n",
       "1                                                     \n",
       "2                                                     \n",
       "3                                                     \n",
       "4                                                     "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backups.columns = backups.columns.str.lower()\n",
    "backups = backups.fillna('')\n",
    "backups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def slugify(string):\n",
    "    string = clean_text(string)\n",
    "    # Remove special characters\n",
    "    string = re.sub(r'[^\\w\\s-]', '', string)\n",
    "    # Replace spaces with hyphens\n",
    "    string = re.sub(r'\\s+', '-', string)\n",
    "    # Convert to lowercase\n",
    "    string = string.lower()\n",
    "    return string\n",
    "\n",
    "def clean_text(string):\n",
    "    # Remove URL prefixes like http:// or https://\n",
    "    # string = re.sub(r'http[s]?://', '', string)\n",
    "    # Remove escape strings like \\n\n",
    "    string = string.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "    # Remove leading '-'\n",
    "    string = re.sub(r'^-', '', string)\n",
    "    # Replace ':' with '-'\n",
    "    string = string.replace(':', '')\n",
    "    return string\n",
    "\n",
    "def get_dataset_categories(agency):\n",
    "    return agency_to_category[agency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_availability(dataset_id):\n",
    "    \"\"\"\n",
    "    This function checks the metadata availability for dataset_id 432 in the backups dataframe.\n",
    "    It returns \"Yes\" if metadata is available, \"Under Review\" if it needs review, and \"No\" otherwise.\n",
    "    \"\"\"\n",
    "    md_avl = backups[backups.dataset_id == dataset_id].metadata_available.values\n",
    "    if \"yes\" in md_avl:\n",
    "\n",
    "        return \"Yes\",backups[backups.dataset_id == dataset_id].metadata_url.values[0]\n",
    "    elif \"needs review\" in md_avl:\n",
    "        return \"Under Review\",\"\"\n",
    "    else:\n",
    "        return \"No\",\"\"\n",
    "\n",
    "def create_dataset_md(row):\n",
    "    if row['organization'] == '':\n",
    "      row['organization'] = 'Unknown'\n",
    "    ## Defining the schema, filename and path\n",
    "    schema = 'data_rescue_project'\n",
    "    dataset_filename = slugify(row['dataset'])\n",
    "    dataset_path = \"_datasets\"\n",
    "    org_filename = slugify(row['organization'])\n",
    "    org_path = \"_organizations\"\n",
    "\n",
    "    ## Get backups for each dataset\n",
    "    data_backups = backups[backups.dataset == row['dataset']]\n",
    "    metadata_available, metadata_url = get_metadata_availability(row['dataset_id'])\n",
    "    ## Creating the dataset markdown file\n",
    "    ## Dataset-level information\n",
    "    dataset_md = \"---\\n\"\n",
    "    dataset_md += f\"schema: {schema} \\n\"\n",
    "    dataset_md += f\"title: {clean_text(row['dataset'])}\\n\"\n",
    "    dataset_md += f\"organization: {clean_text(row['organization'])}\\n\"\n",
    "    dataset_md += f\"agency: {clean_text(row['agency'])}\\n\"\n",
    "    dataset_md += f\"websites: {row['websites']}\\n\"\n",
    "    dataset_md += f\"data_source: {row['url']}\\n\"\n",
    "    dataset_md += f\"description: {clean_text(row['notes'])}\\n\"\n",
    "    dataset_md += f\"last_modified: {row['last_modified']}\\n\"\n",
    "    ## Check if any backups have metadata available and populate\n",
    "    dataset_md += f\"metadata_available: {metadata_available}\\n\"\n",
    "    dataset_md += f\"metadata_url: {metadata_url}\\n\"\n",
    "    dataset_md += f\"category:\\n\"\n",
    "    dataset_md += f\"  - {get_dataset_category(clean_text(row['agency']))}\\n\"\n",
    "\n",
    "    dataset_md += f\"resources:\\n\"\n",
    "    ## Resource-level information\n",
    "    for index, backup_row in data_backups.iterrows():\n",
    "      dataset_md += f\"  - id: {index}\\n\"\n",
    "      dataset_md += f\"    url: {backup_row['download_location']}\\n\"\n",
    "      dataset_md += f\"    format: {clean_text(backup_row['file_type'])}\\n\"\n",
    "      dataset_md += f\"    status: {clean_text(backup_row['status'])}\\n\"\n",
    "      dataset_md += f\"    size: {backup_row['size']}\\n\"\n",
    "      dataset_md += f\"    download_date: {backup_row['download_date']}\\n\"\n",
    "      dataset_md += f\"    maintainer: {clean_text(backup_row['maintainer'])}\\n\"\n",
    "      dataset_md += f\"    notes: {clean_text(backup_row['notes'])}\\n\"\n",
    "    dataset_md += \"---\\n\"\n",
    "      \n",
    "    ## Writing the dataset markdown file\n",
    "    with open(f'{dataset_path}/{dataset_filename}.md', 'w') as output:\n",
    "      output.write(dataset_md)\n",
    "    \n",
    "    ## Creating the organization markdown file\n",
    "    org_md = \"---\\n\"\n",
    "    org_md += f\"title: {clean_text(row['organization'])} \\n\" \n",
    "    org_md += f\"description: \\n\" \n",
    "    org_md += \"---\\n\"\n",
    "\n",
    "    ## Writing the organization markdown file\n",
    "    with open(f'{org_path}/{org_filename}.md', 'w') as output:\n",
    "      output.write(org_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "726    None\n",
       "727    None\n",
       "728    None\n",
       "729    None\n",
       "730    None\n",
       "Length: 731, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.apply(create_dataset_md, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def remove_files_os(dir_path):\n",
    "    for filename in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "if not a:\n",
    "    print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_multiple_spaces(string):\n",
    "    return re.sub(r'\\s+', ' ', string)\n",
    "\n",
    "# Example usage\n",
    "example_string = \"This   is  a   string    with multiple   spaces.\"\n",
    "cleaned_string = replace_multiple_spaces(example_string)\n",
    "print(cleaned_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_files_os('_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    # Remove URL prefixes like http:// or https://\n",
    "    # string = re.sub(r'http[s]?://', '', string)\n",
    "    # Remove escape strings like \\n\n",
    "    string = string.replace('\\n', '').replace('\\r', '').replace('\\t', '')\n",
    "    # Remove multiple spaces\n",
    "    string = re.sub(r'\\s+', ' ', string)\n",
    "    # Remove leading spl. characters\n",
    "    string = re.sub(r'^[^a-zA-Z]+', '', string)\n",
    "    # string = string.lstrip(',')\n",
    "    string = re.sub(r'^-', '', string)\n",
    "    # Remove leading and trailing ':'\n",
    "    string = string.rstrip(':')\n",
    "    string = re.sub(r'(?<!http)(?<!https):', '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdcC01557/html#'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string = \",https://www.ncei.noaa.gov/metadata/geoportal/rest/metadata/item/gov.noaa.ncdcC01557/html#\"\n",
    "clean_text(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = test_string.lstrip(',')\n",
    "print(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from create_markdowns import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m remove_files_os(\u001b[33m'\u001b[39m\u001b[33m../_organizations\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m remove_files_os(\u001b[33m'\u001b[39m\u001b[33m../_dataset_categories\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mcreate_markdowns\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DataRescue_jkan/python/create_markdowns.py:194\u001b[39m, in \u001b[36mcreate_markdowns\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    192\u001b[39m organizations = organizations.fillna(\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Remove files in _datasets and _organizations\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[43mremove_files_os\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./_datasets\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m remove_files_os(\u001b[33m'\u001b[39m\u001b[33m./_organizations\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    196\u001b[39m remove_files_os(\u001b[33m'\u001b[39m\u001b[33m./_dataset_categories\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/DataRescue_jkan/python/create_markdowns.py:35\u001b[39m, in \u001b[36mremove_files_os\u001b[39m\u001b[34m(dir_path)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mremove_files_os\u001b[39m(dir_path):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     36\u001b[39m         file_path = os.path.join(dir_path, filename)\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.isfile(file_path):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './_datasets'"
     ]
    }
   ],
   "source": [
    "def remove_files_os(dir_path):\n",
    "    for filename in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "            \n",
    "# Remove files in _datasets and _organizations\n",
    "remove_files_os('../_datasets')\n",
    "remove_files_os('../_organizations')\n",
    "remove_files_os('../_dataset_categories')\n",
    "\n",
    "create_markdowns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Climate & Environment']\n",
      "['Climate & Environment', 'Humanitarian & Disaster Relief']\n"
     ]
    }
   ],
   "source": [
    "organizations = pd.read_csv(\"https://raw.githubusercontent.com/datarescueproject/portal/refs/heads/main/baserow_exports/datarescue_organizations.csv\")\n",
    "print(organizations[organizations['Organizations'] == 'National Oceanic and Atmospheric Administration']['Categories'].str.split(';').values[0])\n",
    "print(organizations[organizations['Organizations'] == 'Department of the Interior']['Categories'].str.split(';').values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organizations</th>\n",
       "      <th>Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>American Battle Monuments Commission</td>\n",
       "      <td>Arts &amp; Culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barry Goldwater Scholarship and Excellence in ...</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consumer Financial Protection Bureau</td>\n",
       "      <td>Business &amp; Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delta Regional Authority</td>\n",
       "      <td>Business &amp; Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Denali Commission</td>\n",
       "      <td>Business &amp; Economy;Infrastructure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>Federal Mediation and Conciliation Service</td>\n",
       "      <td>Labor &amp; Employment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Health Resources and Services Administration</td>\n",
       "      <td>Health &amp; Healthcare;Social Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>Institute of International Education</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>U.S. Patent and Trademark Office</td>\n",
       "      <td>Business &amp; Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>National Center for Education Statistics</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Organizations  \\\n",
       "0                 American Battle Monuments Commission   \n",
       "1    Barry Goldwater Scholarship and Excellence in ...   \n",
       "2                 Consumer Financial Protection Bureau   \n",
       "3                             Delta Regional Authority   \n",
       "4                                    Denali Commission   \n",
       "..                                                 ...   \n",
       "416         Federal Mediation and Conciliation Service   \n",
       "417       Health Resources and Services Administration   \n",
       "418               Institute of International Education   \n",
       "419                   U.S. Patent and Trademark Office   \n",
       "420           National Center for Education Statistics   \n",
       "\n",
       "                              Categories  \n",
       "0                         Arts & Culture  \n",
       "1                              Education  \n",
       "2                     Business & Economy  \n",
       "3                     Business & Economy  \n",
       "4      Business & Economy;Infrastructure  \n",
       "..                                   ...  \n",
       "416                   Labor & Employment  \n",
       "417  Health & Healthcare;Social Services  \n",
       "418                            Education  \n",
       "419                   Business & Economy  \n",
       "420                            Education  \n",
       "\n",
       "[421 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array = organizations.values.flatten()\n",
    "print(combined_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "backups = pd.read_csv(\"https://raw.githubusercontent.com/datarescueproject/portal/refs/heads/main/baserow_exports/datarescue_backups.csv\")\n",
    "datasets = pd.read_csv(\"https://raw.githubusercontent.com/datarescueproject/portal/refs/heads/main/baserow_exports/datarescue_datasets.csv\")\n",
    "organizations = pd.read_csv(\"https://raw.githubusercontent.com/datarescueproject/portal/refs/heads/main/baserow_exports/datarescue_organizations.csv\")\n",
    "\n",
    "backups.columns = backups.columns.str.lower()\n",
    "backups = backups.fillna('')\n",
    "backups.head()\n",
    "\n",
    "datasets.columns = datasets.columns.str.lower()\n",
    "datasets = datasets.fillna('')\n",
    "datasets.head()\n",
    "\n",
    "organizations = organizations.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets[datasets['dataset'].str.contains(\"Environmental Justice\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_md(datasets.loc[54],backups, organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = datasets.loc[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if row['organization'] == '':\n",
    "    row['organization'] = 'Unknown'\n",
    "# Defining the schema, filename and path\n",
    "schema = 'data_rescue_project'\n",
    "dataset_filename = slugify(row['dataset'])\n",
    "dataset_path = \"../_datasets\"\n",
    "org_filename = slugify(row['organization'])\n",
    "org_path = \"../_organizations\"\n",
    "\n",
    "# Get backups for each dataset\n",
    "data_backups = backups[backups.dataset == row['dataset']]\n",
    "metadata_available, metadata_url = get_metadata_availability(row['dataset_id'], data_backups)\n",
    "# Creating the dataset markdown file\n",
    "# Dataset-level information\n",
    "dataset_md = \"---\\n\"\n",
    "dataset_md += f\"schema: {schema} \\n\"\n",
    "dataset_md += f\"title: {clean_text(row['dataset'])}\\n\"\n",
    "dataset_md += f\"organization: {clean_text(row['organization'])}\\n\"\n",
    "dataset_md += f\"agency: {clean_text(row['agency'])}\\n\"\n",
    "dataset_md += f\"websites: {clean_text(row['websites'])}\\n\"\n",
    "dataset_md += f\"data_source: {clean_text(row['url'])}\\n\"\n",
    "dataset_md += f\"description: {clean_text(row['notes'])}\\n\"\n",
    "dataset_md += f\"last_modified: {row['last_modified']}\\n\"\n",
    "# Check if any backups have metadata available and populate\n",
    "dataset_md += f\"metadata_available: {metadata_available}\\n\"\n",
    "dataset_md += f\"metadata_url: {clean_text(metadata_url)}\\n\"\n",
    "dataset_md += \"category:\\n\"\n",
    "cats = get_dataset_category(row, organizations)\n",
    "\n",
    "for cat in cats:\n",
    "    dataset_md += f\"  - {cat} \\n\"\n",
    "    \n",
    "dataset_md += \"resources:\\n\"\n",
    "# Resource-level information\n",
    "for index, backup_row in data_backups.iterrows():\n",
    "    dataset_md += f\"  - id: {index}\\n\"\n",
    "    dataset_md += f\"    url: {clean_text(backup_row['download_location'])}\\n\"\n",
    "    dataset_md += f\"    format: {clean_text(backup_row['file_type'])}\\n\"\n",
    "    dataset_md += f\"    status: {clean_text(backup_row['status'])}\\n\"\n",
    "    dataset_md += f\"    size: {backup_row['size']}\\n\"\n",
    "    dataset_md += f\"    download_date: {backup_row['download_date']}\\n\"\n",
    "    dataset_md += f\"    maintainer: {clean_text(backup_row['maintainer'])}\\n\"\n",
    "    dataset_md += f\"    notes: {clean_text(backup_row['notes'])}\\n\"\n",
    "dataset_md += \"---\\n\"\n",
    "    \n",
    "# Writing the dataset markdown file\n",
    "with open(f'{dataset_path}/{dataset_filename}.md', 'w') as output:\n",
    "    output.write(dataset_md)\n",
    "\n",
    "# Creating the organization markdown file\n",
    "org_md = \"---\\n\"\n",
    "org_md += f\"title: {clean_text(row['organization'])} \\n\" \n",
    "org_md += \"description: \\n\" \n",
    "org_md += \"---\\n\"\n",
    "\n",
    "# Writing the organization markdown file\n",
    "with open(f'{org_path}/{org_filename}.md', 'w') as output:\n",
    "    output.write(org_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_category(row, organizations):\n",
    "    # Check if dataset has category override\n",
    "    categories = eval(row['categories'])\n",
    "    if categories:\n",
    "        cats = [a['value'] for a in categories]\n",
    "    # Check if we don't have organization info\n",
    "    elif row['organization'] == 'Unknown':\n",
    "        cats = ['Uncategorized']\n",
    "    else:\n",
    "        # Get categories from organization\n",
    "        cats_from_org = organizations[organizations['Organizations'] == row['organization']]['Categories'].values\n",
    "        cats = []\n",
    "        [cats.extend(v.split(';')) for v in cats_from_org]      \n",
    "        cats = list(set(cats))\n",
    "        if cats == ['']:\n",
    "            cats = ['Uncategorized']\n",
    "        else:\n",
    "            cats = [cat for cat in cats if cat != '']\n",
    "    \n",
    "    return cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Climate & Environment', 'Health & Healthcare']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataset_category(datasets.loc[54], organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets[datasets['dataset'].str.startswith('20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393    None\n",
       "395    None\n",
       "396    None\n",
       "397    None\n",
       "398    None\n",
       "399    None\n",
       "400    None\n",
       "401    None\n",
       "403    None\n",
       "404    None\n",
       "405    None\n",
       "407    None\n",
       "408    None\n",
       "409    None\n",
       "410    None\n",
       "416    None\n",
       "640    None\n",
       "662    None\n",
       "663    None\n",
       "665    None\n",
       "666    None\n",
       "667    None\n",
       "696    None\n",
       "697    None\n",
       "698    None\n",
       "798    None\n",
       "799    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.apply(create_dataset_md, axis=1, args=(backups, organizations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_category(row):\n",
    "    # Check if dataset has category override\n",
    "    categories = eval(row['categories'])\n",
    "    if categories:\n",
    "        cats = [a['value'] for a in categories]\n",
    "    # Check if we don't have organization info\n",
    "    elif row['organization'] == 'Unknown':\n",
    "        cats = ['Uncategorized']\n",
    "    else:\n",
    "        # Get categories from organization\n",
    "        cats_from_org = organizations[organizations['Organizations'] == row['organization']]['Categories'].values\n",
    "        cats = []\n",
    "        [cats.extend(v.split(';')) for v in cats_from_org]      \n",
    "        cats = list(set(cats))\n",
    "        if cats == ['']:\n",
    "            cats = ['Uncategorized']\n",
    "        else:\n",
    "            cats = [cat for cat in cats if cat != '']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ''\n",
    "len(a.split(';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organizations</th>\n",
       "      <th>Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Organizations, Categories]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "organizations[organizations['Categories']== np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASEROW_ACCESS_TOKEN = 'rS0kZr4TRauacDsiObLy2Zly512HVd3S'\n",
    "\n",
    "def stringify_arr_vals(arr):\n",
    "    return ';'.join([i['value'] for i in arr])\n",
    "\n",
    "def get_results_json(url):\n",
    "    table = requests.get(\n",
    "        url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Token {BASEROW_ACCESS_TOKEN}\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    res = table.json()['results']\n",
    "    if table.json()['next'] is not None:\n",
    "        res.extend(get_results_json(table.json()['next']))\n",
    "\n",
    "    return res\n",
    "\n",
    "# categories = pd.DataFrame(get_results_json(\"https://baserow.datarescueproject.org/api/database/rows/table/732/?user_field_names=true\"))[['Name', 'Active']]\n",
    "# organizations = pd.DataFrame(get_results_json(\"https://baserow.datarescueproject.org/api/database/rows/table/638/?user_field_names=true\"))[['Organizations', 'Categories']]\n",
    "# organizations['Categories'] = organizations['Categories'].apply(lambda x: stringify_arr_vals(x))\n",
    "# categories.to_csv(\"baserow_exports/datarescue_categories.csv\", index=False)\n",
    "# organizations.to_csv(\"baserow_exports/datarescue_organizations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agencies = pd.DataFrame(get_results_json(\"https://baserow.datarescueproject.org/api/database/rows/table/645/?user_field_names=true\"))[['Name']]\n",
    "agencies.to_csv(\"../baserow_exports/datarescue_agencies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agency_md(row):\n",
    "    \"\"\"\n",
    "    This function creates a markdown file for each agency.\n",
    "    \"\"\"\n",
    "    agency_path = \"../_agencies\"\n",
    "    agency_filename = slugify(row['Name'])\n",
    "\n",
    "    # Creating the agency markdown file\n",
    "    agency_md = \"---\\n\"\n",
    "    agency_md += f\"title: {clean_text(row['Name'])} \\n\"\n",
    "    agency_md += \"description: \\n\"\n",
    "    agency_md += \"---\\n\"\n",
    "\n",
    "    # Writing the agency markdown file\n",
    "    with open(f'{agency_path}/{agency_filename}.md', 'w') as output:\n",
    "        output.write(agency_md)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     None\n",
       "1     None\n",
       "2     None\n",
       "3     None\n",
       "4     None\n",
       "      ... \n",
       "72    None\n",
       "73    None\n",
       "74    None\n",
       "75    None\n",
       "76    None\n",
       "Length: 77, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agencies.apply(create_agency_md, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
